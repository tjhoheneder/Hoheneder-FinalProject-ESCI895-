{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hoheneder-ESCI895-FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZpZmOPeluzkP",
        "CjcEQr9qwQ9b",
        "FfM3HUBswoou",
        "xj-Q3eT1w6Lj",
        "tCORhimMxGsj",
        "uPklKjruyb7X",
        "R1OJ75Ev222v",
        "zx6SeiOy2_q0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Hoheneder Final Term Project:**\n",
        "\n",
        "## <center> **Spatial Evaluation of the Cheat River Watershed Hydrograph Response to a Large Storm Event**\n",
        "\n",
        "<center> Study Site: Cheat River Watershed in North-Central, West Virginia, USA\n",
        "\n",
        "ESCI895: Hydrologic Data Analysis, Fall 2021\n",
        "\n",
        "University of New Hampshire"
      ],
      "metadata": {
        "id": "ZpZmOPeluzkP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIlPqNCAuvl1"
      },
      "outputs": [],
      "source": [
        "#%% Description of Dataset and Purpose of Code: \n",
        "\n",
        "#Description: \n",
        "# Project File Taking Numerous Stream Gauges for a Given Watershed Area and Evaluating How That Pulse of Water\n",
        "#Moves Through The Given Watershed for a Single Storm Event\n",
        "\n",
        "#Major Products Inlcude: Time Series Plots, Z-Score Values of Discharge, Basic Stats of Discharge Comparison\n",
        "\n",
        "#Major Conclusion: The Storm Event Factors More on the Path of the Storm than the Site Hydrologic Properties \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Libraries for Project: \n",
        "import pandas as pd\n",
        "import datetime\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "metadata": {
        "id": "DQzDOwEYvRCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Introduction**\n",
        "\n",
        "**Central Project Goals:** \n",
        "\n",
        "* How does peak discharge temporally vary within a watershed for a single large-scale flooding event? \n",
        "* How does discharge move thorugh a watershed during a storm event? \n",
        "* Is it possible to track th location of a storm within a watershed based upon the hydrograph? \n",
        "* What insight does monitoring discharge provide those seeking to mitigate the damage of flooding in the future? \n",
        "\n",
        ".\n",
        "\n",
        "**Introducion to Project:**\n",
        "\n",
        "This project seeks to address how water specifically moved through the Cheat River watershed during a large-sclae flooding event in 2019. The magnitude of this flooding event slighlty compares to the largest flooding events for the watershed which took place in 1985. **The Election Day Floods of 1985** caused damages in excess of **$700M** to West Virginia which was found “woefully underprepared” for floods of such magnitude (Luke, 1988, “Response to West Virginia’s...”). Evaluating how large discharge events move throughout a watershed temporally and in magnitude can provide insight into what steps can be taken to mitigate damage and harm to communities and their residents, as well as developing a hydrologic comprehension of how water is temporally and geographically intertwined to a watershed area. In the context of West Virginia, centering hydrologic research upon the Cheat River basin seeks to evaluate and defend an **understudied** and **historically disadvantaged** region of the United States in disaster preparedness.\n",
        "\n",
        "\n",
        "Discharge data for the 2019 event will be employed in lieu of the 1985 Election Day Floods due to scant data coverage for the 1985 event. While suitable coverage can be found for the USGS network during 2019, the same cannot be said for 1985 where only two operational discharge gauges were located within the watershed at the time of the storm event. Hence, a proxy for the catastrophic 1985 flooding events will be replaced with the 2019 highly-covered flooding event. \n",
        "\n",
        ".\n",
        "\n",
        "**Impact of Study:**\n",
        "\n",
        "In the context of West Virginia, centering hydrologic research upon the Cheat River basin seeks to evaluate and defend an **understudied** and **historically disadvantaged** region of the United States in disaster preparedness. This study aims to not only produce information that is useful in a global hydrologic sense where it can be applied to numerous watersheds and storm events, but especially looks towards areas where natural disaster resource allocation and preparedness is lacking. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CjcEQr9qwQ9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Importing Raw Datafiles: \n",
        "\n",
        "#Importing Data Files: \n",
        "albright_file= 'Albright.txt'\n",
        "blackwater_file= 'Blackwater.txt'\n",
        "bowden_file= 'Bowden.txt'\n",
        "hendricks_file = 'Hendricks.txt'\n",
        "parsons_file= 'Parsons.txt'\n",
        "rockville_file= 'Rockville.txt'"
      ],
      "metadata": {
        "id": "hro-oRaYwZ0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **The Cheat River Watershed of North Central West Virginia:**\n",
        "\n",
        "\n",
        "**The Cheat River Watershed:** \n",
        "\n",
        "The Cheat River watershed is a 3682.9km2 catchment located entirely within **North-Central West Virginia** where the Cheat River proper flows 135km northward from the confluence of Shavers Fork and the Blackwater River to eventually terminate at Point Marion, PA, as the larger Monongahela River as a portion of the greater Ohio River network. \n",
        "\n",
        ".\n",
        "\n",
        "**Major Tributaries of the Cheat River Watershed:**\n",
        "*   Shavers Fork\n",
        "*   Blackwater River\n",
        "*   Big Sandy Creek\n",
        "*   Dry Fork\n",
        "*   Dry Run\n",
        "*   Glady Fork\n",
        "*   Laurel Fork\n",
        "\n",
        ".\n",
        "\n",
        "**Geography of the Cheat River Watershed:**\n",
        "\n",
        "The Cheat River watershed is dominated by deciduous forest land cover, where the National Land Cover Dataset (NLCD) identifies over 85% of the watershed area as **deciduous forest** land cover. \n",
        "\n",
        "The watershed area is bordered by the **Appalachian Front** physiographic boundary to the east resulting in larger quantities of precipitation in the catchment with an average of 101.59 mm/yr with a maximum of 149.28 mm/yr in the southern extreme of the watershed adjacent to **Cheat Mountain**, from which the watershed receives its name. \n",
        "\n",
        "Given the physiographic boundaries of the watershed, elevation also dramatically varies with the eastern border of the watershed composed of the **Appalachian Front** terminus of the **Valley and Ridge** physiographic province, gradually losing elevation westward into the **Appalachian High Plateaus** towards the **Ohio River Valley**. "
      ],
      "metadata": {
        "id": "FfM3HUBswoou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Importing DataFrames:  \n",
        "\n",
        "#Albright:\n",
        "df_albright= pd.read_table(albright_file, delimiter=\"\\t\", comment='#', \n",
        "                   header=1, parse_dates=['20d'], index_col=['20d'], \n",
        "                   na_values= [9999, -9999, 8888, -8888])\n",
        "#Drop Columns: \n",
        "df_albright= df_albright.drop(columns={\"5s\", \"15s\", \"6s\", \"10s\", \"10s.1\"})\n",
        "#Rename Columns: \n",
        "df_albright= df_albright.rename(columns={\"14n\": \"Discharge (cfs)\"})\n",
        "df_albright= df_albright.rename(columns={\"14n.1\": \"Stage (ft)\"})\n",
        "#Fill NaN Data: \n",
        "df_albright.interpolate(method = 'linear', inplace = True)\n",
        "\n",
        "#Blackwater: \n",
        "df_blackwater= pd.read_table(blackwater_file, delimiter=\"\\t\", comment='#', \n",
        "                   header=1, parse_dates=['20d'], index_col=['20d'], \n",
        "                   na_values= [9999, -9999, 8888, -8888])\n",
        "#Drop Columns: \n",
        "df_blackwater= df_blackwater.drop(columns={\"5s\", \"15s\", \"6s\", \"10s\"})\n",
        "#Rename Columns: \n",
        "df_blackwater= df_blackwater.rename(columns={\"14n\": \"Discharge (cfs)\"})\n",
        "df_blackwater= df_blackwater.rename(columns={\"14n.1\": \"Stage (ft)\"})\n",
        "#Fill NaN Data: \n",
        "df_blackwater.interpolate(method = 'linear', inplace = True)\n",
        "    \n",
        "#Bowden: \n",
        "df_bowden= pd.read_table(bowden_file, delimiter=\"\\t\", comment='#', \n",
        "                   header=1, parse_dates=['20d'], index_col=['20d'], \n",
        "                   na_values= [9999, -9999, 8888, -8888])\n",
        "#Drop Columns: \n",
        "df_bowden= df_bowden.drop(columns={\"5s\", \"15s\", \"6s\", \"10s\"})\n",
        "#Rename Columns: \n",
        "df_bowden= df_bowden.rename(columns={\"14n\": \"Discharge (cfs)\"})\n",
        "df_bowden= df_bowden.rename(columns={\"14n.1\": \"Stage (ft)\"})\n",
        "#Fill NaN Data: \n",
        "df_bowden.interpolate(method = 'linear', inplace = True)\n",
        "    \n",
        "#Hendricks: \n",
        "df_hendricks= pd.read_table(hendricks_file, delimiter=\"\\t\", comment='#', \n",
        "                   header=1, parse_dates=['20d'], index_col=['20d'], \n",
        "                   na_values= [9999, -9999, 8888, -8888])\n",
        "#Drop Columns: \n",
        "df_hendricks= df_hendricks.drop(columns={\"5s\", \"15s\", \"6s\", \"10s\"})\n",
        "#Rename Columns: \n",
        "df_hendricks= df_hendricks.rename(columns={\"14n\": \"Discharge (cfs)\"})\n",
        "df_hendricks= df_hendricks.rename(columns={\"14n.1\": \"Stage (ft)\"})\n",
        "#Fill NaN Data: \n",
        "df_hendricks.interpolate(method = 'linear', inplace = True)  \n",
        "    \n",
        "#Parsons: \n",
        "df_parsons= pd.read_table(parsons_file, delimiter=\"\\t\", comment='#', \n",
        "                   header=1, parse_dates=['20d'], index_col=['20d'], \n",
        "                   na_values= [9999, -9999, 8888, -8888])\n",
        "#Drop Columns: \n",
        "df_parsons= df_parsons.drop(columns={\"5s\", \"15s\", \"6s\", \"10s\", \"10s.1\"})\n",
        "#Rename Columns: \n",
        "df_parsons= df_parsons.rename(columns={\"14n\": \"Discharge (cfs)\"})\n",
        "df_parsons= df_parsons.rename(columns={\"14n.1\": \"Stage (ft)\"})\n",
        "#Fill NaN Data: \n",
        "df_parsons.interpolate(method = 'linear', inplace = True)\n",
        "    \n",
        "#Rockville: \n",
        "df_rockville= pd.read_table(rockville_file, delimiter=\"\\t\", comment='#', \n",
        "                   header=1, parse_dates=['20d'], index_col=['20d'], \n",
        "                   na_values= [9999, -9999, 8888, -8888])\n",
        "#Drop Columns: \n",
        "df_rockville= df_rockville.drop(columns={\"5s\", \"15s\", \"6s\", \"10s\"})\n",
        "#Rename Columns: \n",
        "df_rockville= df_rockville.rename(columns={\"14n\": \"Discharge (cfs)\"})\n",
        "df_rockville= df_rockville.rename(columns={\"14n.1\": \"Stage (ft)\"})\n",
        "#Fill NaN Data: \n",
        "df_rockville.interpolate(method = 'linear', inplace = True)\n"
      ],
      "metadata": {
        "id": "exw3kUATwp2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Establishing the Study Sites Within the Cheat River Watershed:**\n",
        "\n",
        "This study employs a series of six streamflow gauges operated by the **United States Geological Survey (USGS)** to evaluate the properties of 15-min intervals of streamflow discharge, in cubic feet per second moving throughout the Cheat River watershed of a specific large storm event in late-June 2019. This storm event was the single largest storm event for the Cheat River Watershed in terms of discharge during the 2019 calendar year. \n",
        "\n",
        "**Streamflow Guages of Study:**\n",
        "* Dry Fork at Hendricks, WV (USGS: 03065000)\n",
        "* Blackwater River at Davis, WV (USGS: 03066000)\n",
        "* Shavers Fork below Bowden, WV (USGS: 03068800)\n",
        "* Cheat River near Parsons, WV (USGS: 03069500)\n",
        "* Cheat River at Albright, WV (USGS: 03070260)\n",
        "* Big Sandy Creek at Rockville, WV (USGS: 03070500)\n",
        "\n",
        "\n",
        "All streamflow gauges within the extent of the Cheat River HUC-8 watershed were selected for this study and were found to be operational for the full extent of the storm event. All data was gathered from the USGS as a portion of the NWIS hydrologic database. As depicted above, the streamflow gauges within the Cheat River watershed are distributed across all of the major tributaries so that no major tributary or another source of channelized hydrologic contribution to the Cheat River hydrologic network is missing from the storm event analysis. "
      ],
      "metadata": {
        "id": "xj-Q3eT1w6Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Create List of DataFrames and Constants for Functions and Looping: \n",
        "\n",
        "#Create List of Gauge Station DataFrames: \n",
        "df_list= [df_albright, df_blackwater, df_bowden, df_hendricks, df_parsons, df_rockville]\n",
        "\n",
        "#Define Watershed Area: \n",
        "watershed_area= 1422 #sq-mi\n",
        "\n",
        "#Define Start and End Dates--Initial Load Includes a Second Storm I Want to Avoid: \n",
        "starting_date= pd.to_datetime('2019-06-28 00:00:00')\n",
        "ending_date= pd.to_datetime('2019-07-05 00:00:00')\n"
      ],
      "metadata": {
        "id": "9-CQzJOuwBxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Trim DataFrames to Desried Lengths--This Refuses to Work in a Function (See Below): \n",
        "\n",
        "#Define Function for Trimming DataFrames: \n",
        "def time_trim(df):\n",
        "    #Trim DataFrames:\n",
        "    df= df[starting_date:ending_date]\n",
        "    return df    \n",
        "\n",
        "#Iterative For Loop to Trim DataFrames: \n",
        "for item in df_list: \n",
        "    time_trim(item) #Doesn't Trim DataFrames???\n",
        "\n",
        "#Text Output Statement to Let Me Know For Loop Ran: \n",
        "print('')\n",
        "print('DataFrames Trimmed')\n",
        "print('')\n",
        "\n",
        "#Trim DataFrame--For Real This Time: \n",
        "df_albright_trim= df_albright[starting_date:ending_date]\n",
        "df_blackwater_trim= df_blackwater[starting_date:ending_date]\n",
        "df_bowden_trim= df_bowden[starting_date:ending_date]\n",
        "df_hendricks_trim= df_hendricks[starting_date:ending_date]\n",
        "df_parsons_trim= df_parsons[starting_date:ending_date]\n",
        "df_rockville_trim= df_rockville[starting_date:ending_date]\n",
        "\n",
        "#Create df_trim List: \n",
        "df_trim_list = [df_albright_trim, df_blackwater_trim, df_bowden_trim, df_hendricks_trim, \n",
        "                df_parsons_trim, df_rockville_trim]"
      ],
      "metadata": {
        "id": "5_Kbyl32w-4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Methodology:**\n",
        "\n",
        "The methodology of this study is based on upon evaluating how similar or dissimilar numerous discharge curves are to one another over the course of a single significant storm event. \n",
        "\n",
        "The means of determining how event flow properties vary not only in quantity, but temporally across an array of USGS gauges can be determined in two major steps: **baseflow-event flow hydrograph separation** and a **curve similarity approximation**. Both of these steps can be completed in the realm of time-series analysis, where hydrograph separation serves as a vehicle to identify the means of comparison, and a curve similarity approximation serves as the method of comparison and analysis. From these steps, other interrelated products, such as spatial interpolations of event flow properties can be produced across the watershed area extent. \n",
        "\n",
        ".\n",
        "\n",
        "**Major Methodlogical Processes:**\n",
        "* Visualization of Discharge Curves for the Storm Event\n",
        "* Hydrograph Seperation of Baseflow from Event Flows\n",
        "* Pearson Coefficient Generation for Curve Similarity Analysis\n",
        "\n",
        ". \n",
        "\n",
        "All data for this was completed utilizing the Python coding software suite, and all analysis was conducted using the associated Python coding packages of **NumPy** and **Pandas**. Data downloaded from the USGS NWIS hydrologic database was used to retrieve 15-min discharge data for all six gauges from the Cheat River watershed into a single conglomerated timeseries. This single timeseries was converted to a single Pandas dataframe per stream gauge location for data manipulation purposes. \n",
        "\n",
        "Within this dataframe, the index included the date and time of each discharge measurement and each column specified the discharge measurement, in cubic feet per second (cfs) of each of the six USGS gauge locations. Following entry into the Python platform, equivalent values of discharge were found for each measurement in terms of discharge in cm/hr as a product of the total watershed extent and a normalized z-score value to identify the degree of variance from normal of each discharge value. \n",
        "\n"
      ],
      "metadata": {
        "id": "tCORhimMxGsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% DataFrame Operations: \n",
        "\n",
        "#Define Function for Z-Score Calculations: \n",
        "def zscore_Q(df):\n",
        "    #Calculate Z-Score for DataFrame:\n",
        "    df['Z-Score Q']= (df['Discharge (cfs)'] - df['Discharge (cfs)'].mean()) / df['Discharge (cfs)'].std()\n",
        "\n",
        "#Define Function for Discharge Equivalence in cm/hr: \n",
        "def discharge_cmhr(df): \n",
        "    #Calculate Discharge in cm/hr: \n",
        "    df['Discharge (cm/hr)']= (df['Discharge (cfs)']/watershed_area * (1/5280**2) * 30.48 * 3600)\n",
        "\n",
        "#For Loop to Calculate Z-Score for Each DataFrame: \n",
        "for item in df_list:\n",
        "    #Iterate For Loop to Calculate Z-Scores:\n",
        "    zscore_Q(item)\n",
        "    #Iterate For Loop to Calculate Discharge Equivalence: \n",
        "    discharge_cmhr(item)\n",
        "\n",
        "for item in df_trim_list:\n",
        "    #Iterate For Loop to Calculate Z-Scores:\n",
        "    zscore_Q(item)\n",
        "    #Iterate For Loop to Calculate Discharge Equivalence: \n",
        "    discharge_cmhr(item)\n",
        "\n",
        "#Output Text Statement: \n",
        "print('Calculated Z-Scores for DataFrames')\n",
        "print('')\n",
        "print('Discharge Equivalence in cm/hr Calculated for Each DataFrame')\n",
        "print('')\n"
      ],
      "metadata": {
        "id": "ACK0aZbLxbZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Plotting Discharge Time Series**\n",
        "\n",
        "Generating time series to visualize how discharge progressed for the storm event across each of the six measurment gauges. Plots were generated as time series for dependent values of discharge. Plotting these raw time series allows for a visualization of the discharge curves preceeding any analysis of their timing and curve geometry. \n",
        "\n",
        "**Time Series Iterations:**\n",
        "* Discharge (cm/hr)\n",
        "* Discharge (Z-Score)\n",
        "\n",
        "As this study exclusively focuses upon the 2019 Cheat River flooding event, the temporal period of observation was limited to **3 days (June 27th, 2019)** preceding the storm event, throughout the duration of the storm event, and terminating **7 days (July 7th, 2019)** following the end of precipitation. This period was selected as it allowed for the most cohesive estimation of baseflow conditions as a relatively normal rate of baseflow without the significant influence of precipitation could be determined. \n",
        "\n",
        "The major visual product of this step is the time series displaying the rise and fall of the hydrograph over the duration of the period of study representing the movement of the storm system through the watershed as a hydrologic pulse. Each line in the time series plot represents a different USGS streamflow gauge such that the magnitude of flow can be visually inferred. Given hydrologic discharge data does not typically display any significant seasonality trends in the roughly two week period this study observes, no need for further time series manipulation or extraction of residual values was seen as necessary analysis. "
      ],
      "metadata": {
        "id": "CzZxcm92xez2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Plotting Initial Time Series Curves Over Full Duration: \n",
        "\n",
        "#Create Plotting Area:     \n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "#Plot Discharge Data: \n",
        "#Albright:\n",
        "ax1.plot(df_albright_trim['Discharge (cm/hr)'], ',', linestyle='-', color='navy', label='Albright')\n",
        "#Blackwater: \n",
        "ax1.plot(df_blackwater_trim['Discharge (cm/hr)'], ',', linestyle='-', color='grey', label='Davis')\n",
        "#Bowden: \n",
        "ax1.plot(df_bowden_trim['Discharge (cm/hr)'], ',', linestyle='-', color='dodgerblue', label='Bowden')\n",
        "#Hendricks: \n",
        "ax1.plot(df_hendricks_trim['Discharge (cm/hr)'], ',', linestyle='-', color='maroon', label='Hendricks')\n",
        "#Parsons: \n",
        "ax1.plot(df_parsons_trim['Discharge (cm/hr)'], ',', linestyle='-', color='orange', label='Parsons')\n",
        "#Rockville: \n",
        "ax1.plot(df_rockville_trim['Discharge (cm/hr)'], ',', linestyle='-', color='darkgreen', label='Rockville')\n",
        "\n",
        "#Axis Formatting: \n",
        "ax1.set_ylim(bottom = 0)\n",
        "ax1.set_xlim(df_albright_trim.index[0], df_albright_trim.index[-1])\n",
        "fig.autofmt_xdate()\n",
        "\n",
        "#Axis Labels: \n",
        "ax1.set_ylabel('Discharge (cm/hr)', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "ax1.set_xlabel('Date', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "fig.suptitle('Discharge Curves for Cheat River Watershed', fontweight= \"bold\", fontsize=18)\n",
        "\n",
        "#Legend: \n",
        "fig.legend(bbox_to_anchor= (1.15, 0.75)) "
      ],
      "metadata": {
        "id": "nnqTz2fHxj5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Plotting Initial Time Series Curve Z-Scores Over Full Duration: \n",
        "\n",
        "#Create Plotting Area:     \n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "#Plot Discharge Data: \n",
        "#Albright:\n",
        "ax1.plot(df_albright_trim['Z-Score Q'], ',', linestyle='-', color='navy', label='Albright')\n",
        "#Blackwater: \n",
        "ax1.plot(df_blackwater_trim['Z-Score Q'], ',', linestyle='-', color='grey', label='Blackwater')\n",
        "#Bowden: \n",
        "ax1.plot(df_bowden_trim['Z-Score Q'], ',', linestyle='-', color='dodgerblue', label='Bowden')\n",
        "#Hendricks: \n",
        "ax1.plot(df_hendricks_trim['Z-Score Q'], ',', linestyle='-', color='maroon', label='Hendricks')\n",
        "#Parsons: \n",
        "ax1.plot(df_parsons_trim['Z-Score Q'], ',', linestyle='-', color='orange', label='Parsons')\n",
        "#Rockville: \n",
        "ax1.plot(df_rockville_trim['Z-Score Q'], ',', linestyle='-', color='darkgreen', label='Rockville')\n",
        "\n",
        "#Axis Formatting: \n",
        "ax1.set_xlim(df_albright_trim.index[0], df_albright_trim.index[-1])\n",
        "fig.autofmt_xdate()\n",
        "\n",
        "#Axis Labels: \n",
        "ax1.set_ylabel('Discharge (cm/hr)', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "ax1.set_xlabel('Date', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "fig.suptitle('Z-Scored Discharge Curves for Cheat River Watershed', \n",
        "             fontweight= \"bold\", fontsize=18)\n",
        "\n",
        "#Legend: \n",
        "fig.legend(bbox_to_anchor= (1.15, 0.75)) "
      ],
      "metadata": {
        "id": "lzKwSJm4xn44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Hydrograph Seperation of Discharge Curves:**\n",
        "\n",
        "This first major step of this study's methoodlogy is the speration of raw discharge values into subsequent values of **baseflow** and **event flow**. The seperation of hydrograph values is a critical step as it allows for the evaluation of the watershed's response to new, input volumes of water in its system (Blume et al., 2007). The watershed's response provides insight regarding how affecteda  given hydrologic channel is based upon the magnitude of water input to the water body. \n",
        "\n",
        "* **Baseflow:** The sustaining flow of a river system; the approximated discharge of the river system independent of additional hydrological inputs\n",
        "\n",
        "* **Event Flow:** Discharge quantity above the base flow discharge. Effectively, the response of the hydrograph to a particular storm event in terms of discharge\n",
        "\n",
        "\n",
        "For the purposes of this study, seperating values into baseflow and event flow discharge allows for the evaluation of when peak discharge arrived, how much total discharge was associated with the storm event, and how those values compare temporally and in magnitude across the six gauges in the Cheat River watershed. All values were normalized into a z-score value. Normalization of discharge values to a z-score value ensures that the order of magnitude across various streamflow gauges is being represented in a common scale. While all streamflow gauges inherently will increase with any given amount of positive net water input into the system, morphological factors such as channel depth, width, and other considerations all greatly affect how flow moves through the channel at the point of measurement (Crinklaw, 2018). Normalization to a z-score largely bypasses fluvial morphological factors where the dependent discharge is not only common across all stream gauges, but is more representative of the specific channel conditions than a value of raw discharge.  \n"
      ],
      "metadata": {
        "id": "eUFefGnextuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Hydrograph Seperation Function: \n",
        "\n",
        "#Define Function:\n",
        "def hydrograph_sep(totalq, watershed):\n",
        "\n",
        "    #Find totalq: \n",
        "    totalq['Diff'] = totalq['Discharge (cm/hr)'].diff()\n",
        "    \n",
        "    #Find Antecedent Discharge and Date using 0.000104 Threshold: \n",
        "    global antQ_date\n",
        "    antQ = (totalq.loc[totalq['Diff'] > 0.000104, 'Discharge (cm/hr)'])\n",
        "    antQ_date = antQ.index[0]\n",
        "    antQ_val = round(antQ[0], 3)\n",
        "    \n",
        "    #Find Peak Discharge Date: \n",
        "    peakQ_date = totalq['Discharge (cm/hr)'].idxmax()\n",
        "    peakQ = totalq['Discharge (cm/hr)'].max()   \n",
        "    \n",
        "    #Calculate Event Duration:\n",
        "    N = 0.82*(watershed*1e-6)**0.2\n",
        "    #Calculate End of Event: \n",
        "    global end_of_event\n",
        "    end_of_event = peakQ_date + datetime.timedelta(days = N)\n",
        "    \n",
        "    #Calculate Ending Discharge Value: \n",
        "    end_Q = totalq.iloc[totalq.index.get_loc(end_of_event,method='nearest'), \n",
        "                        totalq.columns.get_loc('Discharge (cm/hr)')]\n",
        "    \n",
        "    #Create baseQ Dataframe:\n",
        "    global baseQ\n",
        "    baseQ = totalq[['Discharge (cm/hr)']].copy()\n",
        "    \n",
        "    #Calculate Base Discharge Curve Before Peak: \n",
        "    slope1, intercept1= np.polyfit(totalq.loc[totalq.index < antQ_date].index.astype('int64')\n",
        "                                /1E9, totalq.loc[totalq.index < antQ_date, 'Discharge (cm/hr)'], 1) \n",
        "\n",
        "    #Append Data Before Peak: \n",
        "    baseQ.loc[antQ_date:peakQ_date,\"Discharge (cm/hr)\"] = slope1 * (totalq.loc[antQ_date:peakQ_date].index.view('int64')/1e9) + intercept1\n",
        "    \n",
        "    #Calculate Base Discharge Curve After Peak: \n",
        "    slope2, intercept2= np.polyfit([peakQ_date.timestamp(), end_of_event.timestamp()], \n",
        "                               [baseQ.loc[peakQ_date, 'Discharge (cm/hr)'], end_Q], 1)\n",
        "    \n",
        "    #Append Data After Peak: \n",
        "    baseQ.loc[peakQ_date:end_of_event,\"Discharge (cm/hr)\"] = slope2 * (totalq.loc[peakQ_date:end_of_event].index.view('int64')/1e9) + intercept2\n",
        "    \n",
        "    #Append BaseQ Values to DataFrame: \n",
        "    totalq['BaseQ (cm/hr)'] = baseQ['Discharge (cm/hr)']\n",
        "    \n",
        "    #Return Variables: \n",
        "    return (baseQ, antQ_date, antQ_val, peakQ_date, peakQ, end_of_event, end_Q)\n"
      ],
      "metadata": {
        "id": "BLT9v2P_xxZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Modified Time Series Plotting Containing Baseflow: \n",
        "    \n",
        "#Define Function with Keyword Arguement for Baseflow: \n",
        "def timeseriesplot(df1, startdate, enddate, baseflow= None):    \n",
        "\n",
        "    #Create Plot Area: \n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    #Plot Discharge Data: \n",
        "    ax1.plot(df1['Discharge (cm/hr)'], ',', linestyle='-', color='navy', label='Discharge (cm/hr)')\n",
        "\n",
        "    #Axis Formatting: \n",
        "    ax1.set_ylim(bottom = 0)\n",
        "    ax1.set_xlim(startdate, enddate)\n",
        "    fig.autofmt_xdate()\n",
        "\n",
        "    #Axis Labels: \n",
        "    ax1.set_ylabel('Discharge (cm/hr)', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "    ax1.set_xlabel('Date', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "    \n",
        "    #Optional Arguement Boolean Indicator: \n",
        "    if baseflow is not None: \n",
        "        ax1.plot(baseflow['Discharge (cm/hr)'], ',', linestyle='-', color='darkseagreen', \n",
        "                 label=' Baseflow (cm/hr)')\n",
        "    \n",
        "    #Legend: \n",
        "    fig.legend(bbox_to_anchor= (0.65, 0.0))  "
      ],
      "metadata": {
        "id": "8Wlt3gMXx3Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Creating Values of Event Discharge**\n",
        "\n",
        "To determine the volume of discharge across the storm event, the baseflow discharge value was subtracted from the event flow value. In this sense, a value of event flow is determined for the system that rises above the typical, antecedent, baseflow discharge. This is the movement of excess water that is moving through the system at a given time, and creates the “pulse” of the storm event through the Cheat River watershed. \n",
        "\n",
        "* **$Q_{Event} = Q_{Observed}  - Q_{Base}$**\n",
        "\n",
        "Relatedly, once this effective flow value is calculated, to determine the total volume of effective flow discharge of the storm event, the effective flow discharge curve was integrating over the duration of the storm event. This provides a volumetric measurement of how much water moved through the point of measurement throughout the storm event. "
      ],
      "metadata": {
        "id": "xy3eozcIx_0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Determine Effective Flow: \n",
        "\n",
        "#Define Function: \n",
        "def effect_flow(df): \n",
        "    #Calculate Effective Flow: \n",
        "    #Ensure All Values of Event Flow are Positive: \n",
        "    df['BaseQ (cm/hr)']= np.where(df['BaseQ (cm/hr)'] > 0, df['BaseQ (cm/hr)'], 0)\n",
        "    #Redefine Values of Event Flow Equal to Discharge as 0: \n",
        "    df['Eff Flow (cm/hr)']= np.where(df['Discharge (cm/hr)'] - df['BaseQ (cm/hr)'] > 0,  \n",
        "                                     df['Discharge (cm/hr)'] - df['BaseQ (cm/hr)'], 0)\n",
        "        \n",
        "#Create For Loop to Run Function for Each DataFrame: \n",
        "for item in df_list:\n",
        "    #Run Event Flow-Effect Flow Function: \n",
        "    effect_flow(item)\n",
        "\n",
        "#Output Text Statement to Confirm For Loop:\n",
        "print('')\n",
        "print('Event Flow Calculated for Each DataFrame')\n",
        "print('')\n"
      ],
      "metadata": {
        "id": "izznIJuVyGtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Calculate Z-Score for Effective Flow:  \n",
        "\n",
        "#Define Fnction: \n",
        "def zscore_eventflow(df):\n",
        "    #Create Z-Score for Event Flow: \n",
        "    df['Z-Score EffQ']= (df['Eff Flow (cm/hr)'] - df['Eff Flow (cm/hr)'].mean()) / df['Eff Flow (cm/hr)'].std() \n",
        "\n",
        "#For Loop to Iterate Through: \n",
        "for item in df_list: \n",
        "    #Iterate Thorugh Function: \n",
        "    zscore_eventflow(item)\n",
        "    \n",
        "#Let Me Know This Ran: \n",
        "print('Solved Z-Score for Event Flows')\n",
        "print('')\n"
      ],
      "metadata": {
        "id": "79OcHG8qyS-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Calculating Pearson Coefficient Values for Discharge Curve Correlation**\n",
        "\n",
        "The last step of this study is to determine how similar or different the various discharge curves are to each other. A measure of similairty of discharge profiles will provide the information we are seeking regarding determining how a storm event moves thorughout a watershed.\n",
        "\n",
        "\n",
        "A Pearson correlation will generate a coefficient value between -1 and 1 that indicates whether the time series being evaluated are:\n",
        "\n",
        "* **Positively Correlated (1)**\n",
        "* **Not Correlated (0)**\n",
        "* **Negatively Correlated (-1)**\n",
        "\n",
        "\n",
        "Given the Pearson coefficient is a global rating of synchrony between multiple datasets, an assumption is made to neglect small, spatial phenomena that influence discharge, such as fluctuating temperatures above freezing. It is expected the effects of these phenomena, if present, are temporary and minute enough that they will not affect the global synchrony and correlation of any of the time series."
      ],
      "metadata": {
        "id": "Y-5PpjYqy27R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Pearson Coefficient Calculation for Time Series: \n",
        "\n",
        "#Create Empty Array to Store PEarson Values for Comparison: \n",
        "pearson_array= []    \n",
        "\n",
        "#Albright-Davis Correlation: \n",
        "AlbrightDavisQ=df_albright['Discharge (cm/hr)'].corr(df_blackwater['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(AlbrightDavisQ)\n",
        "\n",
        "#Albright-Bowden Correlation: \n",
        "AlbrightBowdenQ=df_albright['Discharge (cm/hr)'].corr(df_bowden['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(AlbrightBowdenQ)\n",
        "    \n",
        "#Albright-Hendricks Correlation: \n",
        "AlbrightHendricksQ=df_albright['Discharge (cm/hr)'].corr(df_hendricks['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(AlbrightHendricksQ)\n",
        "\n",
        "#Albright-Parsons Correlation:\n",
        "AlbrightParsonsQ=df_albright['Discharge (cm/hr)'].corr(df_parsons['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(AlbrightParsonsQ)    \n",
        "\n",
        "#Albright-Rockville Correlation: \n",
        "AlbrightRockvilleQ=df_albright['Discharge (cm/hr)'].corr(df_rockville['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(AlbrightRockvilleQ)\n",
        "\n",
        "#Davis-Bowden:\n",
        "DavisBowdenQ=df_blackwater['Discharge (cm/hr)'].corr(df_bowden['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(DavisBowdenQ)    \n",
        "\n",
        "#Davis-Hendricks:\n",
        "DavisHendricksQ=df_blackwater['Discharge (cm/hr)'].corr(df_hendricks['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(DavisHendricksQ)    \n",
        "\n",
        "#Davis-Parsons:\n",
        "DavisParsonsQ=df_blackwater['Discharge (cm/hr)'].corr(df_parsons['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(DavisParsonsQ)\n",
        "\n",
        "#Davis-Rockville: \n",
        "DavisRockvilleQ=df_blackwater['Discharge (cm/hr)'].corr(df_rockville['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(DavisRockvilleQ)\n",
        "\n",
        "#Bowden-Hendricks: \n",
        "BowdenHendricksQ=df_bowden['Discharge (cm/hr)'].corr(df_hendricks['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(BowdenHendricksQ)    \n",
        "\n",
        "#Bowden-Parsons: \n",
        "BowdenParsonsQ=df_bowden['Discharge (cm/hr)'].corr(df_parsons['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(BowdenParsonsQ)    \n",
        "\n",
        "#Bowden-Rockville: \n",
        "BowdenRockvilleQ=df_bowden['Discharge (cm/hr)'].corr(df_rockville['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(BowdenRockvilleQ)\n",
        "\n",
        "#Hendricks-Parsons: \n",
        "HendricksParsonsQ=df_hendricks['Discharge (cm/hr)'].corr(df_parsons['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(HendricksParsonsQ)    \n",
        "\n",
        "#Hendricks-Rockville: \n",
        "HendricksRockvilleQ=df_hendricks['Discharge (cm/hr)'].corr(df_rockville['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(HendricksRockvilleQ)\n",
        "\n",
        "#Parsons-Rockville: \n",
        "ParsonsRockvilleQ=df_parsons['Discharge (cm/hr)'].corr(df_rockville['Discharge (cm/hr)'])\n",
        "#Append to List: \n",
        "pearson_array.append(ParsonsRockvilleQ)\n"
      ],
      "metadata": {
        "id": "bri_g8gvyzSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Creating Small DataFrame for Pearson Values: \n",
        "      \n",
        "#List of Gauge Combinations for Reference: \n",
        "ref_list = ['Albright-Davis', 'Albrihgt-Bowden', 'Albright-Hendricks', 'Albright-Parsons', 'Albright-Rockville', \n",
        "            'Davis-Bowden', 'Davis-Hendricks', 'Davis-Parsons', 'Davis-Rockville', \n",
        "            'Bowden-Hendricks', 'Bowden-Parsons', 'Bowden-Rockville', \n",
        "            'Hendricks-Parsons', 'Hendricks-Rockville', \n",
        "            'Parsons-Rockville']\n",
        "  \n",
        "# Calling DataFrame constructor after Zipping:\n",
        "pearsondf = pd.DataFrame(list(zip(ref_list, pearson_array)),\n",
        "               columns =['Gauge Combination', 'Pearson Coefficient Value'])\n"
      ],
      "metadata": {
        "id": "rLVp5fZW2C2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Results of the Study:**\n",
        "\n",
        "**Major Results Products:**\n",
        "* Time Series of Discharge Isolating Each Location Displaying Baseflow and Event Flow Discharge  \n",
        "* Conglomerated Time Series of Event Flow Discharges by Location in terms of cm/hr and Z-Scores\n",
        "* Bar Graph Comparing the Total Discharge Volume by Location for the Storm Event\n",
        "* Table of Basic Statistics of Event Flow by Location \n",
        "* Table and Bar Graph of Pearson Coefficient Values by Coupled Stream Gauge Location Combination \n",
        "\n"
      ],
      "metadata": {
        "id": "uPklKjruyb7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First Cell to Dirve Results"
      ],
      "metadata": {
        "id": "lwNetvnCyi5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Hydrograph Seperation Function to Visualize and Quantify Baseflow**\n",
        "\n",
        "Generation of **Time Series Curves** for each study site location in terms of cm/hr discharge for the seperate **baseflow** and **observed discharge** curves. A line of event flow is not included on these plots, but is calculated in the background of the below functions. As previoulsy mentioned, baseflow can never exceed the observed discahrge, such for periods of time not identified with the storm event, baseflow was assumed to be equal to the observed discharge. This was done to not need to extract the inlfuence of previous storm events or other influences onto the rising limb discharge curve.  \n",
        "\n",
        "**What Does This Show?:**\n",
        "* What Are the Baseflow and Event Flow Discharge Values for a Given Site?\n",
        "* How Does Baseflow and Event Flow Vary in Magnitude Over Time? \n",
        "* How Does the Baseflow Relate Itself to the Event Flow for a Specific Site?    "
      ],
      "metadata": {
        "id": "Xtdmz7ulzEv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Running Functions per Watershed: \n",
        "\n",
        "#Create Empty Array for Storm Totals: \n",
        "storm_totals = []    \n",
        "\n",
        "#Define Function for Running Functions per Watershed: \n",
        "def watershed_function(df):\n",
        "    #Run Hydrograph Seperation Function: \n",
        "        (baseQ, antQ_date, antQ_val, peakQ_date, peakQ, end_of_event, end_Q) = hydrograph_sep(df, watershed_area)\n",
        "        #Integrating Storm Total: \n",
        "        storm_frame= df[antQ_date : end_of_event]\n",
        "        discharge_total= storm_frame['Discharge (cm/hr)'].sum()\n",
        "        storm_totals.append(discharge_total)\n",
        "        #Run Time Series Plotting Function: \n",
        "        timeseriesplot(df, df.index[0], df.index[-1], baseQ)\n",
        "\n",
        "#For Loop to Iterate Through Locations: \n",
        "for item in df_list: \n",
        "    watershed_function(item)\n",
        "\n",
        "#Output Text Statement to Let Me Know This Ran: \n",
        "print('')\n",
        "print('Congrats, You Probably Have Some Graphs Now...')\n",
        "print('')\n"
      ],
      "metadata": {
        "id": "kajAE_SjzTSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Visualziation of Event Flow Discharge Curves**\n",
        "\n",
        "Generation of Time Series Curves for Each Location in terms of cm/hr discharge and Z-Score values. These plots dispaly the result of the previous iterative plots of observed discharge and baseflow. Such, this is the subtractive product of those individual plots. As previously mentioned, baseflow was assumed to be equal to observed flow for periods outside of the storm event duration to not require to analyze the influence of previous storm events on the hydrograph or other outside influences. \n",
        "\n",
        "**What Does This Show?:**\n",
        "* How does the magnitude of peak event flow vary by site?\n",
        "* How does the magnitude of event flow discharge change over time?\n",
        "* How do the curves of event flow discharge vary from site to site?   "
      ],
      "metadata": {
        "id": "mMsT-tqPzUUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Plotting Effective Flow Curves Over Full Duration: \n",
        "\n",
        "#Define Function for Variable Plotting Windows: \n",
        "def eventflow_plotting(start_window, end_window):     \n",
        "\n",
        "    #Create Plotting Area:     \n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    #Plot Discharge Data: \n",
        "    #Albright:\n",
        "    ax1.plot(df_albright['Eff Flow (cm/hr)'], ',', linestyle='-', color='navy', label='Albright')\n",
        "    #Blackwater: \n",
        "    ax1.plot(df_blackwater['Eff Flow (cm/hr)'], ',', linestyle='-', color='grey', label='Blackwater')\n",
        "    #Bowden: \n",
        "    ax1.plot(df_bowden['Eff Flow (cm/hr)'], ',', linestyle='-', color='dodgerblue',  label='Bowden')\n",
        "    #Hendricks: \n",
        "    ax1.plot(df_hendricks['Eff Flow (cm/hr)'], ',', linestyle='-', color='maroon', label='Hendricks')\n",
        "    #Parsons: \n",
        "    ax1.plot(df_parsons['Eff Flow (cm/hr)'], ',', linestyle='-', color='orange', label='Parsons')\n",
        "    #Rockville: \n",
        "    ax1.plot(df_rockville['Eff Flow (cm/hr)'], ',', linestyle='-', color='darkgreen', label='Rockville')\n",
        "\n",
        "    #Axis Formatting: \n",
        "    ax1.set_ylim(bottom = 0)\n",
        "    ax1.set_xlim(df_albright.index[start_window], df_albright.index[end_window])\n",
        "    fig.autofmt_xdate()\n",
        "\n",
        "    #Axis Labels: \n",
        "    ax1.set_ylabel('Discharge (cm/hr)', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "    ax1.set_xlabel('Date', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "    fig.suptitle('Event Flow Discharge Curves for Cheat River Watershed', fontweight= \"bold\", fontsize=18)\n",
        "\n",
        "    #Legend: \n",
        "    fig.legend(bbox_to_anchor= (1.15, 0.75))  \n",
        "\n",
        "#Function for Full Duration: \n",
        "eventflow_plotting(0, -1)\n",
        "    \n",
        "#Function for Zoomed-In Duration: \n",
        "eventflow_plotting(275, -675) \n"
      ],
      "metadata": {
        "id": "34ml17n6zcb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Plotting Z-Scored Effective Flow Curves Over Full Duration: \n",
        "\n",
        "#Create Function for Z-Score Plotting:     \n",
        "def zscore_event_plotting(start_window, end_window): \n",
        "    \n",
        "    #Create Plotting Area:     \n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    #Plot Discharge Data: \n",
        "    #Albright:\n",
        "    ax1.plot(df_albright['Z-Score EffQ'], ',', linestyle='-', color='navy', label='Albright')\n",
        "    #Blackwater: \n",
        "    ax1.plot(df_blackwater['Z-Score EffQ'], ',', linestyle='-', color='grey', \n",
        "         label='Blackwater')\n",
        "    #Bowden: \n",
        "    ax1.plot(df_bowden['Z-Score EffQ'], ',', linestyle='-', color='dodgerblue', label='Bowden')\n",
        "    #Hendricks: \n",
        "    ax1.plot(df_hendricks['Z-Score EffQ'], ',', linestyle='-', color='maroon', \n",
        "         label='Hendricks')\n",
        "    #Parsons: \n",
        "    ax1.plot(df_parsons['Z-Score EffQ'], ',', linestyle='-', color='orange', label='Parsons')\n",
        "    #Rockville: \n",
        "    ax1.plot(df_rockville['Z-Score EffQ'], ',', linestyle='-', color='darkgreen', \n",
        "         label='Rockville')\n",
        "\n",
        "    #Axis Formatting: \n",
        "    ax1.set_xlim(df_albright.index[start_window], df_albright.index[end_window])\n",
        "    fig.autofmt_xdate()\n",
        "\n",
        "    #Axis Labels: \n",
        "    ax1.set_ylabel('Discharge (cm/hr)', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "    ax1.set_xlabel('Date', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "    fig.suptitle('Z-Scored Event Discharge Curves', \n",
        "             fontweight= \"bold\", fontsize=18)\n",
        "\n",
        "    #Legend: \n",
        "    fig.legend(bbox_to_anchor= (1.15, 0.75))     \n",
        "\n",
        "#Function for Full Duration: \n",
        "zscore_event_plotting(0, -1)\n",
        "    \n",
        "#Function for Selected Window: \n",
        "zscore_event_plotting(275, -675)\n"
      ],
      "metadata": {
        "id": "H7HiyL1FzfGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Plotting Volumes of Total Discharge per USGS Gauge Location:**\n",
        "\n",
        "This graphical output is the creation of a bar graph plot to display how much water ran through each gauging station for the duration of the full storm event. This plot will help us to graphically represent where a certain volume of flow was located during the storm. In essence, this allows us to view how much water moved through a particular area, and such, perhaps which area the storm was centered upon. \n",
        "\n",
        "\n",
        "\n",
        "**Effectively, this plot is a product of two variables:**  \n",
        "*   Magnitude of Discharge \n",
        "*   Duration of the Storm Event\n",
        "\n",
        "\n",
        "\n",
        "Our purposes will allow us to see that even though these stream gauging locations might vary in scale, if the normalized amount of flow through a specific pattern of stations is visible in this plot, we can begin to decypher how a \"pulse\" of water moves thorughout a watershed during a single large-scale storm event"
      ],
      "metadata": {
        "id": "GaIt46FmzkWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Plotting Total Discharge Storm Event Volumes: \n",
        "\n",
        "#Create Plotting Area: \n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "#Add Data Bars: \n",
        "locations = ['Albright', 'Davis', 'Bowden', 'Hendricks', 'Parsons', 'Rockville']\n",
        "discharge_totals = storm_totals\n",
        "ax.bar(locations, discharge_totals, color = 'dodgerblue')\n",
        "\n",
        "#Axis Labels: \n",
        "ax.set_ylabel('Total Discharge (cm)', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "ax.set_xlabel('Location of Measurement', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "ax.set_title('Total Storm Event Discharge Outputs', fontweight= \"bold\", fontsize=18)\n",
        "    \n",
        "#Display Bar Plot: \n",
        "plt.show() \n"
      ],
      "metadata": {
        "id": "QSO6jLf3zr3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Determine Basic Statistical Properties of Event Flow per USGS Gauge Location:**\n",
        "\n",
        "A list of variables per site location for the duration of the storm event. While not inherrently powerful on their own, each of these metrics provide a point of comparison across each site location. Comparing each of these metrics across the full watershed extent can provide us insight as to what observable trends are present for each of these metrics\n",
        "\n",
        "**Statistics Calculated:**\n",
        "* Maximum Event Discharge\n",
        "* Maximum Observed Discharge\n",
        "* Average Event Discharge\n",
        "* Average Observed Discharge\n",
        "\n",
        "**What Can This Tell Us?:**\n",
        "* How does peak event discharge vary across numerous sites? \n",
        "* How does the average event discharge vary across numerous sites? \n",
        "* How do the different study site gauges vary in magnitude?  "
      ],
      "metadata": {
        "id": "PE_6IGuAzuaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Determine Maximum Values of Discharge: \n",
        "\n",
        "#Create Empty Arrays for Quick Reference of Values: \n",
        "#Maximum Discharge Values: \n",
        "max_q = []\n",
        "max_q_zscore= []\n",
        "\n",
        "#Maximum Event Flow Discharge Values: \n",
        "highest_events= []\n",
        "highest_events_zscore= []\n",
        "\n",
        "#Average Discharge: \n",
        "average_Q= []\n",
        "average_eventQ= []\n",
        "\n",
        "#Function for Max Discharge: \n",
        "def max_discharge(df):\n",
        "    #Calculate Maximum:     \n",
        "    big_q= df['Discharge (cm/hr)'].max()\n",
        "    #Append to List: \n",
        "    max_q.append(big_q)\n",
        "    \n",
        "#Function for Max Discahrge Z-Score: \n",
        "def max_discharge_zscore(df):\n",
        "    big_q_zscore= df['Z-Score Q'].max()\n",
        "    max_q_zscore.append(big_q_zscore)\n",
        "\n",
        "#Function for Max Discharge: \n",
        "def max_event(df):\n",
        "    max_event_val= df['Eff Flow (cm/hr)'].max()\n",
        "    highest_events.append(max_event_val)\n",
        "    \n",
        "#Function for Max Discahrge Z-Score: \n",
        "def max_event_zscore(df):\n",
        "    max_event_valz= df['Z-Score EffQ'].max()\n",
        "    highest_events_zscore.append(max_event_valz)\n",
        "\n",
        "#Function for Average Event Discahrge: \n",
        "def avg_event_discharge(df):\n",
        "    avg_event_valz= df['Eff Flow (cm/hr)'].mean()\n",
        "    average_eventQ.append(avg_event_valz)\n",
        "\n",
        "#Function for Average Discahrge: \n",
        "def avg_discharge(df):\n",
        "    avg_valz= df['Discharge (cm/hr)'].mean()\n",
        "    average_Q.append(avg_valz)\n",
        "\n",
        "#For Loop to Iterate Through Gauges: \n",
        "for item in df_list: \n",
        "    #Iterate Through Functions: \n",
        "    max_discharge(item)\n",
        "    max_discharge_zscore(item)\n",
        "    max_event(item)\n",
        "    max_event_zscore(item)\n",
        "    avg_event_discharge(item)\n",
        "    avg_discharge(item)\n",
        "\n",
        "#Output Text Statement: \n",
        "print('')\n",
        "print('For Loop Complete: Values Appended to Lists')\n",
        "print('')\n"
      ],
      "metadata": {
        "id": "Fz7a--G0z4MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center> **Statistical Evaluation of Pearson Correlation Coefficients:**\n",
        "\n",
        "A list of pearson coefficient curve similarity value per coupled site location for the duration of the storm event. All possible dually-coupled site location combination were utilized for the study and were named on the basis of which two sites each coupling included. A table and visiualzied bar grpah format, along with basic statistics, were produced for the collection of pearson coefficients.\n",
        "\n",
        "While not inherrently powerful on their own, each of these metrics provide a point of comparison across each site location. Comparing each of these metrics across the full watershed extent can provide us insight as to what observable trends are present between any combination of site locations. Effectively, this can provide a means of how a watershed is geographically impact by a given storm event. \n",
        "\n",
        "**Statistics Calculated:**\n",
        "* Maximum Pearson Coefficient\n",
        "* Minimum Pearson Coefficient\n",
        "* Average Pearson Coefficient\n",
        "\n",
        "**What Can This Tell Us?:**\n",
        "* How similar is a discharge curve across study sites?\n",
        "* Does the location of a storm event affect the discharge curve geometry?   \n",
        "* How do the different study site combination pearson coefficients vary in magnitude?  "
      ],
      "metadata": {
        "id": "Pu7AlfPpz-F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Basic Insight to Pearson Coefficients: \n",
        "\n",
        "#Most Similar Gauge Profiles: \n",
        "max_pearson = max(pearson_array)\n",
        "#Output Text Statement: \n",
        "print('')\n",
        "print('The Highest Pearson Coefficient Was %6.4f' %max_pearson)\n",
        "print('')\n",
        "\n",
        "#Least Similar Gauge Profiles: \n",
        "min_pearson = min(pearson_array)\n",
        "#Output Text Statement: \n",
        "print('')\n",
        "print('The Lowest Pearson Coefficient Was %6.4f' %min_pearson)\n",
        "print('')\n",
        "\n",
        "#Average Across Watershed: \n",
        "#Sum of Values: \n",
        "sum_pearson= sum(pearson_array)\n",
        "#LEngth of Array as Proxy of Number of Records: \n",
        "len_pearson= len(pearson_array)\n",
        "#Mean of Array Values: \n",
        "avg_pearson = sum_pearson / len_pearson\n",
        "#Output Text Statement: \n",
        "print('')\n",
        "print('The Average Pearson Coefficient Was %6.4f' %avg_pearson)\n",
        "print('')\n"
      ],
      "metadata": {
        "id": "AHGBF6hm0Fhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Bar Graph to Display Pearson Values Not in Table: \n",
        "\n",
        "#Create Plotting Area: \n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "#Add Data Bars: \n",
        "locations = ref_list\n",
        "bars = pearson_array\n",
        "ax.bar(locations, bars, color = 'navy')\n",
        "\n",
        "#Axis Labels: \n",
        "ax.set_ylabel('Pearson Coefficient Value', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "ax.set_xlabel('USGS Gauge Location Combination', color='k', fontweight=\"bold\", fontsize= 12)\n",
        "ax.set_title('Pearson Coefficient Values by Gauge Station Combination', fontweight= \"bold\", fontsize=18)\n",
        "    \n",
        "#Display Bar Plot: \n",
        "plt.show() \n"
      ],
      "metadata": {
        "id": "QDFH3ftl20A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Discussion of Results**\n",
        "\n",
        "The principle findings of this study are contingent on the geometry of the curves geometries and the storm locations. While it is obvious that discharge curves will vary by location, the results of this study more-so suggests that the discharge curves will vary at a higher degree based upon the location of the storm opposed to a gauge being located in an upstream or downstream position within the watershed. \n",
        "\n",
        "## **Conclusion 1: Magnitude of Discharge is Correlated to the Magnitude of Stream**\n",
        "\n",
        "* In the Z-Scored time series, almost all of the curves displayed a similar curve geometry for the peak discharge value. The only exception to this trend was the Blackwater River in Davis, WV which displayed a dually-peaked curve geometry slighlty lower than that of the other gauges. While the Albright, WV gauge was slighlty delayed in its curve, the curve geometry is similar to the other four gauges. Since this is a time series, this is perhaps more indicative of the storm system moving through the watershed than anything related to the arrival of an increased volume of water.  \n",
        "\n",
        "* The average Pearson Coefficient for all gauges was a value of 0.4729 which displays a decent amount fo correlation even after the average likely being degraded follwoing disimilarities with the Albright and Blackwater gauges. In fact, the Hendricks-Parsons combination displayed a 0.9665 coefficient which is a proxy for curves of 96.65% positive similarity; obviously, incredibly high correlation. This value is not isolated however, as 7 of the 14 gauge combination displayed a Pearson Coefficient above 0.65. \n",
        "\n",
        "##**Conclusion 2: Guages in Similar Locations or Rivers Display Similar Magnitudes of Discharge**\n",
        "\n",
        "* Gauges that are spatially closest to one another are those that often had the highest degree fo similarity to one another. For example, the gauges of Hendricks and Parsons had the single largest Pearson Coefficient value of 0.9665. While distance between any pair of gauges was not described in this study, this pairing is of the two single closest gauges in the study. \n",
        "\n",
        "* Furthermore, this trend seems to hold over other local gauge pairs wherein the pairings of Albright-Rockville, Davis-Parsons, and Davis-Hendricks also all displayed relatively high Pearson Coefficient values between one another. \n",
        "\n",
        "* This trend appears to be independent of the magnitude fo the river itself as the smallest observable discharge gauge (Rockville) was highly correlated with the largest observable discharge gauge (Albright). The opposite was true as well, where rivers of similar size within the Cheat River watershed, such as the Blackwater River (Davis) and Dry Fork (Hendricks) also maintained a high Pearson Coefficient   \n",
        "\n",
        "##**Conclusion 3: The Progress of the Storm System Appears Constant Throughout Most of the Cheat River Watershed**\n",
        "\n",
        "* The high degree of similarity of many of the discharge curves displays that the storm system uniformly progressed over the Cheat River watershed. While this study did not evaluate the quantity or rate of precipitation at each gauge location due to a lack of regular, local data coverage, we can observe highly correlated Pearson Coefficients for many of the gauges showing the hydrograph response was not only of a similar geometry, but a similar timing and magnitude for many of the site location pairs. \n",
        "\n",
        "* Visually, we can see that many of the discharge curves, both for cm/hr and normalized Z-Scores, display a similar progress pattern as well, with a very sharp rise on the rising limb, a pronounced peak, and then a steady exponential fall returning to baseflow conditions. The rate of exponential decay was not observed in this study as well, however the similar curve geometries proxied by the Pearson Coefficient indicate it would likely be similar. \n",
        "\n",
        "* The major \"outlier\" in terms of this storm system was that of the Blackwater River at Davis, WV. A logical explanation of why this site displayed such a different geometry compared to the other gauges is likely the storm did not progress thorugh the area in the same means. Given Davis, WV is immediately located upon the Appalachian Front, perhaps an orographic effect prohibited the same progression of the storm system. \n",
        "   "
      ],
      "metadata": {
        "id": "R1OJ75Ev222v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code Cell to Advance to Next Section Header"
      ],
      "metadata": {
        "id": "uaMctww328ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Major Conclusions of Study:**\n",
        "\n",
        "The goals of this study were successful in terms of evaluating how a single large storm event progresses through and affects the hydrographic response of a given watershed. While it was hypothesized that the influence of the storm event would cascade in an upstream to downstream method within the watershed, this hypothesis was proven false as no correlation seems to be apparent between the magnitude of flow and the positionality of the gauges within the watershed. \n",
        "\n",
        ".\n",
        "\n",
        "However, based upon the trends observed from the pearson coefficients of curve similarity, there is some evidence to state the driving factor of hydrologic repsonse might be associated with the path and location of the storm system opposed to the location of any particular gauge. This is logical, as a watershed extent can often be quite large, and especially in a topographically varied watershed such as the Cheat River watershed area, precipitation is not evenly distributed over the full extent. Different nuanced factors such as the orographic positionality (i.e. windward v. leeward), elevation, and location of the gauging site in reference to other locations are all drivers of how much rainfall a particular area did or did not recieve drinving the hydrologic response. \n",
        "\n",
        ".\n",
        "\n",
        "Additionally, it was assumed all surface conditions within the watershed were fully conservative. All flows in the river were assumed to be instanteously dissapating or cumulative and no contributions were expected to be made to groundwater; a fully conservative model of fate transport. Moving forward, to understand how these conditions might vary across numerous sites, it could be helpful to add an explicitly spatial component to this study in terms of a flow accumulation raster. In those regards, the amount of water in a stream system at any given time can be assumed to move downstream and compared to the observed value. If a consistent ratio of discharge is bieng met on a per-cell basis, then a proxy value of upstream groundwater contribution can be determined. This would greatly improve the future results of the study giving it localized spatial vaildation of results as well as understanding the role other, non-observed, influences play in the movement of event flow in the Cheat River watershed. \n",
        "\n",
        ". \n",
        "\n",
        "As it currently stands, the data produced from this study is most helpful to those in the Cheat River watershed as well as disaster relief policy and community planners. The lingering socioeconomic impacts of the 1985 Election Day Floods and other large-scale flooding events such as the observed 2019 storm event all produce a means of evaluating how the Cheat River interacts with any given storm. Predicting the response of the river not only provides a proxy to assist the communitites, but also provides a basis to understand how a given town will be impacted as well during a larger flooding event. Given these towns and communities are often low-priority sites for disatter relief efforts, providing validation of increased vulnerabily, or modelled and quantified vulnerability, could justify resource allocation being put towards these communities. Essentially, having the quantification of necessary resources, it is more likely that resouces would be allocated towards a community where wastefulness is an economic concern. "
      ],
      "metadata": {
        "id": "zx6SeiOy2_q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code Cell to Advance to the Next Section Header"
      ],
      "metadata": {
        "id": "JsVeEbJX3HHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Works Cited**\n",
        "\n",
        "* Blume, T., Zehe, E., & Bronstert, A. (2007). Rainfall—runoff response, event-based runoff coefficients and hydrograph separation. Hydrological Sciences Journal, 52(5), 843-862.\n",
        "\n",
        "* Carpenter, D. H. (1990). Floods in West Virginia, Virginia, Pennsylvania, and Maryland, November 1985 (Vol. 88, No. 4213). US Department of the Interior, US Geological Survey.\n",
        "\n",
        "* Crinklaw, J. J. T. (2018). Assessment of hydrological drought in Northern Ontario using standardized streamflow index (Doctoral dissertation).\n",
        "\n",
        "* Merriam, E. R., Petty, J. T., O’Neal, M., & Ziemkiewicz, P. F. (2020). Flow-Mediated Vulnerability of Source Waters to Elevated TDS in an Appalachian River Basin. Water, 12(2), 384.\n",
        "\n",
        "* Nix, S., Brahler, M., Fuller, M. E., & Rowland, A. (2021). Cheat Water Resources: Assessing Climatology and Land Cover Trends and Evaluating Flood Risk of the Cheat River.\n",
        "\n",
        "* Petty, J. T., & Barker, J. (2004). Water quality variability in tributaries of the Cheat River, a mined Appalachian Watershed. In 2004 National Meeting of the American Society of Mining and Reclamation and the 25th West Virginia Surface Mine Drainage Task Force. American Society of Mining and Reclamation, Morgantown, West Virginia (pp. 1484-1504).\n",
        "\n",
        "* Ziemkiewicz, P., & Simmons, J. S. (2003). Completed and future projects on the Cheat River and use of TMDL trading. In West Virginia Surface Mine Drainage Task Force Symposium, April.\n"
      ],
      "metadata": {
        "id": "K0wgy9ct3Lnk"
      }
    }
  ]
}